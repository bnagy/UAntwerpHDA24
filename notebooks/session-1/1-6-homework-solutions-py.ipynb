{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwyPXFb04izJ"
   },
   "source": [
    "# Session 1: homework\n",
    "\n",
    "## 1. Exploring datasets: Exercise spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQzqpi0T4izN"
   },
   "source": [
    "### Loading and inspecting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tr66cTQz4izO"
   },
   "source": [
    "Load and inspect `spelling/spelling_utf8.csv`. Read the `README`\n",
    " to get familiar with this dataset and its variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to do this, but it might come in handy one day. The original version of the dataset\n",
    "# was a TSV written in Windows, which uses a different \"character encoding\" sometimes. Normally,\n",
    "# Python always uses \"UTF-8\" (and that is what we would recommend you stick to). If you try to open\n",
    "# a file with the wrong encoding on the wrong machine you will see some confusing errors like this:\n",
    "#\n",
    "# UnicodeDecodeError: 'utf-8' codec can't decode byte 0x95 in position 15048: invalid start byte\n",
    "#\n",
    "# This is how we fixed that for you.\n",
    "\n",
    "# import chardet\n",
    "\n",
    "# with open(\"../datasets/spelling/spelling.tsv\", \"rb\") as f:\n",
    "#     raw = f.read()\n",
    "\n",
    "# chardet.detect(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This only works with the Windows encoding\n",
    "# df = pd.read_csv(\"../datasets/spelling/spelling.tsv\", sep=\"\\t\", encoding=\"Windows-1252\")\n",
    "\n",
    "# This should always work\n",
    "\n",
    "df = pd.read_csv(\"../datasets/spelling/spelling_utf8.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GfHbP9L4izR"
   },
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwAVVdJU4izS"
   },
   "source": [
    "Can we observe an education difference in the number of errors that are made (`error` = 0 vs `error` = 1)? Create a table with `error` (0/1) per educational track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I prefer to have booleans as Python booleans. This is optional.\n",
    "\n",
    "df[\"error\"] = df[\"error\"] == 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"education\")[\"error\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an alternative method that we didn't cover, which is a bit prettier. Check the documentation and see which way you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.education, df.error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxlRB04a4izT"
   },
   "source": [
    "Now convert this table to a proportion table (percentages). In addition, make the table a bit easier on the eye by rounding the percentages to two digits with `round()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JICWuaL4izU"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"education\")[\"error\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOPlB4xQ4izV"
   },
   "source": [
    "##### Question:\n",
    "> How to interpret these percentages?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "> All students are more inclined to *not* make an error than to make an error. But this inclination is stronger as students are in more theory-oriented tracks (= technical and especially general education)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prmTNX1D4izV"
   },
   "source": [
    "Now repeat these steps, but print column totals instead of row totals---in other words, for each value of 'error' the 'education' values should add up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMTghc-L4izW"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"error\")[\"education\"].value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.education, df.error, normalize=\"columns\").round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE2FnsGH4izW"
   },
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TLia4_a4izW"
   },
   "source": [
    "Create a mosaic plot from the original dataframe (raw frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6iajxvb4izX"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "mosaic(df, [\"error\", \"education\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question:\n",
    "> How to interpret the plot?\n",
    "\n",
    "##### Answer:\n",
    "> The plot tells us the same as the table, but in a visual way. We can see that more practice-oriented students make more errors than more theory-oriented students. Furthermore, the amount of data available for the three educational tracks is shown too: we have the most data for technical students, then for general students, then for vocational students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you recreate this plot, but with education on the \"y-axis\" and error on the \"x-axis\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic(df, [\"education\", \"error\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egl6eMrm4izY"
   },
   "source": [
    "## 2. Spanish authors from the Silver Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkG6IdW94izY"
   },
   "source": [
    "In the next session, we'll work with a dataset that contains general information about a number of canonical Spanish authors from the so-called \"Silver Age\" of Hispanic literature. Let us explore this data already with a couple of simple (and not so simple) exercises:\n",
    "\n",
    "\n",
    "- Load the dataset `sp-authors.tsv` from the folder `../datasets/correlaciones`. Pay attention to the extension!\n",
    "- get an overview of the dataframe in the notebook using the 'last thing evaluated' trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrRAJsqH4izY"
   },
   "outputs": [],
   "source": [
    "span_auth = pd.read_csv(\"../datasets/correlaciones/sp-authors.tsv\", sep=\"\\t\")\n",
    "span_auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUY_WsKV4izY"
   },
   "source": [
    "- Inspect this dataset's contents via `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhWh1Xa64izZ"
   },
   "source": [
    "- How many columns are in the dataset? How many rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxXvH9814izZ"
   },
   "source": [
    "- Print the column names that are used in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0v3GiZT4izZ"
   },
   "source": [
    "- What's the number of female authors in the dataset? How many male authors does it contain? Make a barplot of the counts for both genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.gender.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mjndzWr4iza"
   },
   "source": [
    "- Check out the \"life.span\" column, that lists the age of each author at her/his time of death. What was the age of the youngest and oldest author (at their time of death)? What is the range of this column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (check the min and max)\n",
    "\n",
    "span_auth[\"life-span\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjZouyXR4iza"
   },
   "source": [
    "- Calculate the mean and standard deviation for the average for these authors' life spans, **without making use of the functions `mean()` and `std()`**. Use these functions afterwards to verify whether your calculation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = span_auth[\"life-span\"].sum() / span_auth[\"life-span\"].size\n",
    "\n",
    "print(f\"Mean: {m} (Check: {span_auth['life-span'].mean()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = span_auth[\"life-span\"] - span_auth[\"life-span\"].mean()\n",
    "sum_sq_diffs = (diffs * diffs).sum()\n",
    "var = sum_sq_diffs / (span_auth[\"life-span\"].size - 1)\n",
    "sd = var ** (1 / 2)\n",
    "\n",
    "print(f\"SD: {sd} (Check: {span_auth['life-span'].std()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDcZfKiA4izb"
   },
   "source": [
    "- Sort the dataframe by the 'works' column in **descending** order (most works first). Print the names of the first 7 authors by works (most works). Print the names of the last 7 authors by works (fewest works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = span_auth.sort_values(by=\"works\", ascending=False)\n",
    "print(w.head(7)[\"author-fullname\"])\n",
    "print(w.tail(7)[\"author-fullname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could also do it like this:\n",
    "\n",
    "w = span_auth.sort_values(by=\"works\", ascending=False)\n",
    "print(w.head(7)[[\"author-fullname\", \"works\"]])\n",
    "print(w.tail(7)[[\"author-fullname\", \"works\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QY-621R94izb"
   },
   "source": [
    "- Plot the number of \"novels\" that these authors wrote as a function of the number of (other) \"works\" that they produced. What do you observe?\n",
    "\n",
    "##### Answer\n",
    "> There is certainly a correlation between the number of total works and the number of novels. Most of the datapoints are near the origin, with only a few outliers who wrote many works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.plot.scatter(x=\"novels\", y=\"works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POD7Zdu-4izb"
   },
   "source": [
    "- What's the mode of the \"gender\" column in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_auth.gender.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q0XUv714izb"
   },
   "source": [
    "## 3. Queer speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMGXIPSC4izc"
   },
   "source": [
    "In the next session, we'll work with measurements of the \"pitch\" (i.e. the perceived frequency of sound) in the speech of Spanish-speaking adults. The dataset comes from a research project in the field of sociophonetics, in which the pitch of heterosexual men was compared to the pitch of homosexual men, as well as female speakers.\n",
    "\n",
    "- Load this dataset (it's a csv-file!) and dump the summary in a cell (evaluate it). You can find it as: `../datasets/queer/queer_speech.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pd.read_csv(\"../datasets/queer/queer_speech.csv\")\n",
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhN4M6qK4izc"
   },
   "source": [
    "- Calculate the normalized proportion of the number of men and women in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs.sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JY7DHyk4izc"
   },
   "source": [
    "- Create a new data frame, called \"male\", selecting only the male rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsm = qs[qs.sex == \"M\"]\n",
    "qsm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFotHSwq4izc"
   },
   "source": [
    "- The average pitch of a speaker is represented in the column \"meanf0\". Calculate the mean and standard deviation for each of the two sexual orientations among the male speakers. Use a boxplot to compare the values for \"meanf0\" in both categories, including the \"notches\" from the sprint. Describe what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsm.groupby(\"orientation\")[\"meanf0\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=qsm, x=\"orientation\", y=\"meanf0\", notch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SOLUTION: The median of the \"mean f0\" (base formant frequency) is actually slightly lower in the homosexual group. However there are some outliers in the heterosexual group, and more samples, so we will need to do more statistics to know if the differences mean anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the means for each of the two orientations in the male speakers as orange circles to the box plots from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(\n",
    "    data=qsm,\n",
    "    x=\"orientation\",\n",
    "    y=\"meanf0\",\n",
    "    notch=True,\n",
    "    showmeans=True,\n",
    "    meanprops={\n",
    "        \"marker\": \"o\",\n",
    "        \"markerfacecolor\": \"orange\",\n",
    "        \"markeredgecolor\": \"black\",\n",
    "        \"markersize\": \"9\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oWQAEc14izd"
   },
   "source": [
    "Now have a look at the \"f0sd\" column (which represents the standard deviation in pitch for each speaker). Convert this column to z-score and assign the result to a new column in the data.frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zXcabP2B4izd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "qs.insert(8, \"f0sdz\", ss.fit_transform(qs[[\"f0sd\"]]))\n",
    "qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFWdBilO4izd"
   },
   "source": [
    "- *Hard*: Plot the z-scores for the standardized \"f0sd\" column with a box plot, for each of the three groups involved (heterosexual men, homosexual men, heterosexual women). One way is to create a new column for this, that combines \"sex\" and \"orientation\" (Look for help online as to how to do this.) Describe what you see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[\"sexont\"] = qs.sex + \" + \" + qs.orientation\n",
    "sns.boxplot(\n",
    "    data=qs,\n",
    "    x=\"sexont\",\n",
    "    y=\"f0sdz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SOLUTION: The difficult part of this interpretation is remembering what we a looking at. First of all remember that a z-score of 0 is 'average' and the positive and negative values are \"number of standard deviations from the mean\". Now remember that we are scoring the standard deviation of \"f0\" (frequency), in other words \"how much the f0 varied for *this individual*\".\n",
    "\n",
    "> So the chart suggests that averaged across all participants, female speakers had the most overall variation of pitch, homosexual men had less, and heterosexual men *as a group* had the least, but there were a lot of more variable outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way here is another way to add another 'dimension' to boxplots - we can tell seaborn to additionally colour (hue) by another column, effectively getting us the same combinations without creating a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(\n",
    "    data=qs,\n",
    "    x=\"orientation\",\n",
    "    y=\"f0sdz\",\n",
    "    hue=\"sex\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Version History\n",
    "\n",
    "Current: v1.0.1\n",
    "\n",
    "9/18/24: 1.0.0: first draft, BN\n",
    "04/10/24: 1.0.0: typos + proofreading, MK\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-7-home_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
